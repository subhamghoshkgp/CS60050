{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment 2 Part 2 - Principal Component Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this programming assignment, you will implement a decision tree model and PCA algorithm.\n",
    "\n",
    "**For Even Roll Number Students:**\n",
    "\n",
    "* In this part, you have to implement the PCA algorithm to perform dimensionality reduction on the breast cancer dataset.\n",
    "* Dataset: ````breast-cancer.csv```` with ``diagnosis`` as the target variable.\n",
    "\n",
    "**For Odd Roll Number Students:**\n",
    "\n",
    "* In this part, you have to implement the PCA algorithm to perform dimensionality reduction on the wine quality dataset.\n",
    "* Dataset: ````wine-quality.csv```` with ``Customer_Segment`` as the target variable.\n",
    "\n",
    "The assignment zip file (ML_CS60050_A2.zip) contains the respective datasets which will be used in this assignment.\n",
    "\n",
    "You have to write your code in this jupyter notebook. You have to write your code only between ### START CODE HERE ### and ### END CODE HERE ### comments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Submission Instructions\n",
    "\n",
    "Please submit your assignment as a ZIP file that contains a folder named in the following format: `RollNo_ML_A2`. Inside this folder, include two Jupyter notebooks and a Report with the following names:\n",
    "\n",
    "1. `RollNo_A2_Part1.ipynb`\n",
    "2. `RollNo_A2_Part2.ipynb`\n",
    "3. `RollNo_report.pdf`\n",
    "\n",
    "\n",
    "Instructions for the Report:\n",
    "* Summarize results from noiseless and noisy datasets.\n",
    "* Compare performance and note the impact of noise.\n",
    "* Conclude with key findings andÂ implications.\n",
    "\n",
    "Make sure that you replace `RollNo` with your actual roll number in both the folder name and the notebook filenames.\n",
    "\n",
    "For example, if your roll number is `23CS60R11`, the folder should be named `23CS60R11_ML_A2`, and the three files should be named `23CS60R11_A2_Part1.ipynb`, `23CS60R11_A2_Part2.ipynb` and `RollNo_report.pdf`.\n",
    "\n",
    "Submit this ZIP file as your assignment submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Reading and Pre-processing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following function ```load_data```, you have to read the data from the file and store the data into a pandas dataframe. Then you have to create two numpy arrays $X$ and $y$ from the dataframe:\n",
    "\n",
    "+ $X$: Input data of the shape (number of samples, number of input features)\n",
    "+ $y$: Target variable of the shape (number of samples,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CODE REQUIRED ##\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"\n",
    "    This function loads the data into a pandas dataframe and coverts it into X and y numpy arrays\n",
    "\n",
    "    Args:\n",
    "        filepath: File path as a string\n",
    "    Returns:\n",
    "        X: Input data of the shape (# of samples, # of input features)\n",
    "        y: Target variable of the shape (# of sample,)\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE ###\n",
    "    df = pd.read_csv(filepath)\n",
    "    X = df.drop(\"diagnosis\", axis=1).values  # Drop the \"diagnosis\" column and convert to NumPy array\n",
    "    y = df[\"diagnosis\"].values  # Extract the \"diagnosis\" column and convert to NumPy array\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return X,y\n",
    "\n",
    "filepath = None\n",
    "### START CODE HERE ###\n",
    "filepath = (r\"C:\\Users\\HP\\Downloads\\ML_CS60050_A2\\ML_CS60050_A2\\breast-cancer.csv\")\n",
    "### END CODE HERE ###\n",
    "X, y = load_data(filepath)\n",
    "\n",
    "print(\"Shape of X:\",X.shape, \" Shape of y:\",y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Model Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The main steps of the PCA algorithm are as follows:\n",
    "\n",
    "1. Compute the mean of the input data along each feature dimension.\n",
    "2. Subtract the mean from the input data to center it around zero.\n",
    "3. Compute the covariance matrix of the centered input data.\n",
    "4. Compute the eigenvectors and eigenvalues of the covariance matrix.\n",
    "5. Keep only the first `n_components` eigenvectors as the principal components.\n",
    "6. Compute the explained variance ratio for each principal component.\n",
    "7. Transform the input data by projecting it onto the principal components.\n",
    "\n",
    "#### The mean of the input data along each feature dimension is computed as:\n",
    "\n",
    "$$\n",
    "\\boldsymbol{\\mu} = \\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{x}_i\n",
    "$$\n",
    "\n",
    "where $n$ is the number of samples and $\\mathbf{x}_i$ is the feature vector of the $i$th sample.\n",
    "\n",
    "#### The centered input data is computed as:\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_i' = \\mathbf{x}_i - \\boldsymbol{\\mu}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{X}$ is the input data matrix with shape $(n, p)$, $n$ is the number of samples, and $p$ is the number of features.\n",
    "\n",
    "#### The covariance matrix of the centered input data is computed as:\n",
    "\n",
    "$$\n",
    "\\mathbf{C} = \\frac{1}{n-1}\\sum_{i=1}^{n}(\\mathbf{x}_i' \\cdot \\mathbf{x}_i'^T)\n",
    "$$\n",
    "\n",
    "where $\\mathbf{C}$ is the covariance matrix with shape $(p, p)$.\n",
    "\n",
    "#### The eigenvectors and eigenvalues of the covariance matrix are computed as:\n",
    "\n",
    "$$\n",
    "\\mathbf{C} \\cdot \\mathbf{v}_i = \\lambda_i \\cdot \\mathbf{v}_i\n",
    "$$\n",
    "\n",
    "where $\\mathbf{v}_i$ is the $i$th eigenvector with length $p$, and $\\lambda_i$ is the corresponding eigenvalue.\n",
    "\n",
    "#### Here, we keep only the first `n_components` eigenvectors as the principal components.\n",
    "\n",
    "#### The explained variance ratio for each principal component is computed as:\n",
    "\n",
    "$$\n",
    "\\mathrm{ExplainedVarianceRatio_i} = \\frac{\\lambda_i}{\\sum_{j=1}^{p}\\lambda_j}\n",
    "$$\n",
    "\n",
    "where $\\mathrm{ExplainedVarianceRatio_i}$ is the explained variance ratio for the $i$th principal component.\n",
    "\n",
    "#### The transformed data is computed as:\n",
    "\n",
    "$$\n",
    "\\mathbf{X}_{\\text{transformed}} = \\mathbf{X}_{\\text{centered}} \\cdot \\mathbf{V}\n",
    "$$\n",
    "\n",
    "where $\\mathbf{V}$ is the matrix of principal components with shape $(p, k)$, $\\mathbf{X}_{\\text{centered}}$ is the centered input data matrix with shape $(n, p)$, and $\\mathbf{X}_{\\text{transformed}}$ is the transformed data matrix with shape $(n, k)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    \"\"\"\n",
    "    Principal Component Analysis (PCA) class for dimensionality reduction.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_components):\n",
    "        \"\"\"\n",
    "        Constructor method that initializes the PCA object with the number of components to retain.\n",
    "        \n",
    "        Args:\n",
    "        - n_components (int): Number of principal components to retain.\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Fits the PCA model to the input data and computes the principal components.\n",
    "        (HINT: Use numpy's linalg module to compute eigenvalues and eigenvectors)\n",
    "        \n",
    "        Args:\n",
    "        - X (numpy.ndarray): Input data matrix with shape (n_samples, n_features).\n",
    "        \"\"\"\n",
    "        # Compute the mean of the input data along each feature dimension.\n",
    "        mean = np.mean(X, axis=0)\n",
    "        \n",
    "        # Subtract the mean from the input data to center it around zero.\n",
    "        X = X - mean\n",
    "        \n",
    "        # Compute the covariance matrix of the centered input data.\n",
    "        cov = np.cov(X.T)\n",
    "        \n",
    "        # Compute the eigenvectors and eigenvalues of the covariance matrix.\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
    "        \n",
    "        # Keep only the first n_components eigenvectors as the principal components.\n",
    "        self.components = eigenvectors[:,:self.n_components]\n",
    "        \n",
    "        # Compute the total variance of the input data\n",
    "        total_variance = np.sum(eigenvalues)\n",
    "\n",
    "        # Compute the variance explained by each principal component\n",
    "        self.explained_variances = eigenvalues[:self.n_components]\n",
    "\n",
    "        # Compute the explained variance ratio for each principal component\n",
    "        self.explained_variance_ratio_ = self.explained_variances / total_variance\n",
    "        \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transforms the input data by projecting it onto the principal components.\n",
    "        \n",
    "        Args:\n",
    "        - X (numpy.ndarray): Input data matrix with shape (n_samples, n_features).\n",
    "        \n",
    "        Returns:\n",
    "        - transformed_data (numpy.ndarray): Transformed data matrix with shape (n_samples, n_components).\n",
    "        \"\"\"\n",
    "        \n",
    "        transformed_data = X @ self.components \n",
    "        \n",
    "        return transformed_data\n",
    "    \n",
    "    def fit_transform(self, X):\n",
    "        \"\"\"\n",
    "        Fits the PCA model to the input data and computes the principal components then\n",
    "        transforms the input data by projecting it onto the principal components.\n",
    "        \n",
    "        Args:\n",
    "        - X (numpy.ndarray): Input data matrix with shape (n_samples, n_features).\n",
    "        \"\"\"\n",
    "        self.fit(X)\n",
    "        transformed_data = self.transform(X)\n",
    "        return transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Executing the PCA Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the PCA class with the number of principal components to retain (in this case, 2).\n",
    "pca = PCA(2)\n",
    "\n",
    "# Fit the PCA model to the input data X.\n",
    "pca.fit(X)\n",
    "\n",
    "# Print the explained variance ratio for each of the selected principal components.\n",
    "# This shows how much variance each principal component explains in relation to the total variance.\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the input data X using the previously fitted PCA model.\n",
    "X_transformed = pca.transform(X)\n",
    "\n",
    "# Print the shape of the transformed data X.\n",
    "print(\"Shape of transformed X: \", X_transformed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. Visualizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for Plotly\n",
    "df_transformed = pd.DataFrame(X_transformed, columns=[f\"PC{i+1}\" for i in range(X_transformed.shape[1])])\n",
    "df_transformed['target'] = y  # Add the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot using df_transformed\n",
    "fig = px.scatter(df_transformed, x=\"PC1\", y=\"PC2\", color=\"target\")\n",
    "fig.update_layout(\n",
    "    title=\"PCA transformed data\",\n",
    "    xaxis_title=\"PC1\",\n",
    "    yaxis_title=\"PC2\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 1829286,
     "sourceId": 2984728,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30407,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
